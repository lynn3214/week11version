"""
Dataset construction for training samples (å¢å¼ºç‰ˆ).
æ”¯æŒï¼š
1. å•ä¸ª120ms clickç‰‡æ®µ
2. Click trainåºåˆ—ï¼ˆ500msï¼ŒåŒ…å«2-5ä¸ªclickï¼‰
"""

import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional
import soundfile as sf
import json
from tqdm import tqdm
import random

from detection.candidate_finder.dynamic_threshold import ClickCandidate
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from training.augment.pipeline import AugmentationPipeline


class DatasetBuilder:
    """æ„å»ºè®­ç»ƒæ ·æœ¬ï¼šå•click + click trainåºåˆ—ï¼ˆç»Ÿä¸€é•¿åº¦åˆ°500msï¼‰"""
    
    def __init__(self,
                 sample_rate: int = 44100,
                 window_ms: float = 120.0,
                 random_offset_ms: float = 10.0,
                 unified_length_ms: float = 500.0):  # æ–°å¢ï¼šç»Ÿä¸€é•¿åº¦
        """
        Initialize dataset builder.
        
        Args:
            sample_rate: Sample rate (Hz)
            window_ms: Window duration for single clicks (ms)
            random_offset_ms: Random time offset range (ms)
            unified_length_ms: ç»Ÿä¸€æ‰€æœ‰æ ·æœ¬åˆ°æ­¤é•¿åº¦ï¼ˆæ¯«ç§’ï¼‰
        """
        self.sample_rate = sample_rate
        self.window_samples = int(window_ms * sample_rate / 1000)  # 5292æ ·æœ¬
        self.offset_samples = int(random_offset_ms * sample_rate / 1000)
        self.unified_samples = int(unified_length_ms * sample_rate / 1000)  # 22050æ ·æœ¬
        
    # ... [å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜] ...
    
    def _pad_to_unified_length(self, segment: np.ndarray) -> np.ndarray:
        """
        å°†ä»»æ„é•¿åº¦çš„ç‰‡æ®µpaddingåˆ°ç»Ÿä¸€é•¿åº¦ï¼ˆ500msï¼‰
        
        Args:
            segment: è¾“å…¥ç‰‡æ®µï¼ˆå¯èƒ½æ˜¯120msæˆ–500msï¼‰
            
        Returns:
            Paddingåçš„ç‰‡æ®µï¼ˆ500msï¼‰
        """
        if len(segment) >= self.unified_samples:
            return segment[:self.unified_samples]
        
        # ä¸­å¿ƒpaddingï¼ˆå°†åŸç‰‡æ®µæ”¾åœ¨ä¸­é—´ï¼‰
        pad_total = self.unified_samples - len(segment)
        pad_left = pad_total // 2
        pad_right = pad_total - pad_left
        
        # ä½¿ç”¨å¸¸æ•°paddingï¼ˆå¡«å……0ï¼‰
        padded = np.pad(segment, (pad_left, pad_right), mode='constant')
        
        return padded
        
    # ========== åŸæœ‰æ–¹æ³•ä¿æŒä¸å˜ ==========
    
    def build_positive_samples(self,
                              audio: np.ndarray,
                              candidates: List[ClickCandidate],
                              file_id: str) -> List[Dict[str, Any]]:
        """Build positive samples centered on detected clicks."""
        samples = []
        
        for i, candidate in enumerate(candidates):
            offset = random.randint(-self.offset_samples, self.offset_samples)
            center_idx = candidate.peak_idx + offset
            segment = self._extract_centered_window(audio, center_idx)
            
            if segment is not None:
                sample = {
                    'waveform': segment,
                    'label': 1,
                    'file_id': file_id,
                    'candidate_idx': i,
                    'peak_time': candidate.peak_time,
                    'confidence': candidate.confidence_score
                }
                samples.append(sample)
                
        return samples
        
    def build_negative_samples(self,
                      noise_audio: np.ndarray,
                      file_id: str,
                      n_samples: int) -> List[Dict[str, Any]]:
        """Build negative samples from noise(ç»Ÿä¸€é•¿åº¦åˆ°500ms)."""
        samples = []
        
        # ğŸ”§ ä¿®æ”¹1: å¦‚æœå™ªéŸ³å¤ªçŸ­ï¼Œpaddingåˆ°æ‰€éœ€é•¿åº¦
        if len(noise_audio) < self.unified_samples:
            repeats = int(np.ceil(self.unified_samples / len(noise_audio)))
            noise_audio = np.tile(noise_audio, repeats)[:self.unified_samples]
        
        max_start = len(noise_audio) - self.unified_samples
        
        # ğŸ”§ ä¿®æ”¹2: å³ä½¿ max_start == 0 ä¹Ÿç”Ÿæˆæ ·æœ¬
        if max_start < 0:  # åªæœ‰çœŸæ­£å¤ªçŸ­æ‰è·³è¿‡
            return samples
            
        for i in range(n_samples):
            # å¦‚æœå™ªéŸ³åˆšå¥½ç­‰äºæ‰€éœ€é•¿åº¦ï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªç‰‡æ®µ
            if max_start == 0:
                start_idx = 0
            else:
                start_idx = random.randint(0, max_start)
                
            segment = noise_audio[start_idx:start_idx + self.unified_samples]
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ³¨é‡Šæ‰_normalize_segmentè°ƒç”¨
            # å› ä¸ºnoise_audioå·²ç»åœ¨main.pyä¸­è¿›è¡Œäº†RMSå½’ä¸€åŒ–
            # segment = self._normalize_segment(segment)
            
            # ğŸ”§ æ·»åŠ ï¼šç®€å•çš„å³°å€¼é™åˆ¶ï¼ˆé˜²æ­¢æç«¯å¼‚å¸¸å€¼ï¼‰
            peak = np.max(np.abs(segment))
            if peak > 1.0:  # å¦‚æœè¶…è¿‡1.0ï¼ˆç†è®ºä¸Šä¸åº”è¯¥ï¼‰ï¼Œè¿›è¡Œclip
                segment = np.clip(segment, -1.0, 1.0)
            
            sample = {
                'waveform': segment.astype(np.float32),
                'label': 0,
                'file_id': file_id,
                'candidate_idx': -1,
                'peak_time': start_idx / self.sample_rate,
                'confidence': 0.0
            }
            samples.append(sample)
            
        return samples
    
    # ========== æ–°å¢ï¼šClick Trainåºåˆ—ç”Ÿæˆ ==========
    
    def build_click_train_samples(self,
                          click_files: List[Path],
                          n_train_samples: int,
                          train_length_ms: float = 500.0,
                          min_clicks: int = 2,
                          max_clicks: int = 5,
                          ici_range_ms: Tuple[float, float] = (10.0, 80.0),
                          sample_rate: int = None,
                          noise_pool: List[np.ndarray] = None,
                          augmenter: 'AugmentationPipeline' = None) -> List[Dict[str, Any]]:
        """
        æ„å»ºClick Trainåºåˆ—æ ·æœ¬ï¼ˆä¿®å¤ç‰ˆ - æŒç»­èƒŒæ™¯å™ªéŸ³ï¼‰
        
        Args:
            click_files: Clickç‰‡æ®µæ–‡ä»¶åˆ—è¡¨ï¼ˆ.wavï¼‰
            n_train_samples: è¦ç”Ÿæˆçš„trainæ ·æœ¬æ•°é‡
            train_length_ms: Trainåºåˆ—é•¿åº¦ï¼ˆæ¯«ç§’ï¼‰
            min_clicks: æœ€å°‘clickæ•°
            max_clicks: æœ€å¤šclickæ•°
            ici_range_ms: ICIèŒƒå›´ï¼ˆæ¯«ç§’ï¼‰
            sample_rate: é‡‡æ ·ç‡ï¼ˆå¦‚æœNoneåˆ™ä½¿ç”¨self.sample_rateï¼‰
            noise_pool: å™ªéŸ³æ± ï¼ˆç”¨äºSNRæ··åˆï¼‰
            augmenter: å¢å¼ºå™¨å¯¹è±¡
            
        Returns:
            Trainæ ·æœ¬å­—å…¸åˆ—è¡¨
        """
        if sample_rate is None:
            sample_rate = self.sample_rate
        
        train_samples_total = int(train_length_ms * sample_rate / 1000)
        train_samples = []
        
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        if len(click_files) < min_clicks:
            print(f"âš ï¸ Clickæ–‡ä»¶æ•°({len(click_files)})å°‘äºæœ€å°clicksæ•°({min_clicks})")
            return []
        
        # å¦‚æœæ–‡ä»¶æ•°å°‘äºmax_clicksï¼Œè°ƒæ•´max_clicks
        actual_max_clicks = min(max_clicks, len(click_files))
        if actual_max_clicks < max_clicks:
            print(f"âš ï¸ Clickæ–‡ä»¶æ•°ä¸è¶³ï¼Œå°†max_clicksè°ƒæ•´ä¸º {actual_max_clicks}")
        
        for train_idx in tqdm(range(n_train_samples), desc="ç”ŸæˆClick Trainåºåˆ—"):
            try:
                # 1. éšæœºé€‰æ‹©clickæ•°é‡å’Œæ–‡ä»¶
                n_clicks = random.randint(min_clicks, actual_max_clicks)
                selected_files = random.sample(click_files, n_clicks)
                
                # 2. åŠ è½½clickéŸ³é¢‘
                clicks = []
                for cf in selected_files:
                    audio, sr = sf.read(cf)
                    
                    # é‡é‡‡æ ·
                    if sr != sample_rate:
                        import librosa
                        audio = librosa.resample(audio, orig_sr=sr, target_sr=sample_rate)
                    
                    # è½¬å•å£°é“
                    if audio.ndim == 2:
                        audio = audio.mean(axis=1)
                    
                    # ğŸ”§ ä¿®å¤ï¼šRMSå½’ä¸€åŒ–ï¼ˆå…³é”®æ­¥éª¤ï¼‰
                    rms = np.sqrt(np.mean(audio**2))
                    if rms > 1e-8:
                        target_rms = 0.1
                        audio = audio * (target_rms / rms)
                    
                    # å³°å€¼è£å‰ª
                    peak = np.max(np.abs(audio))
                    if peak > 0.95:
                        audio = audio / peak * 0.95
                    
                    clicks.append(audio)
                
                # 3. æ”¾ç½®clicksï¼ˆå åŠ åˆ°é›¶åˆå§‹åŒ–çš„æ•°ç»„ï¼‰
                train_audio = self._place_clicks_with_realistic_ici(
                    clicks, train_samples_total, ici_range_ms, sample_rate
                )
                
                if train_audio is None:
                    continue
                
                # 4. SNRæ··åˆï¼šæ¨¡æ‹ŸçœŸå®æµ·æ´‹ç¯å¢ƒï¼ˆæŒç»­èƒŒæ™¯å™ªå£° + clicksï¼‰
                if noise_pool is not None and augmenter is not None:
                    #if random.random() < augmenter.apply_prob:
                    if True:  # å§‹ç»ˆåº”ç”¨SNRæ··åˆ
                        # 4.1 é€‰æ‹©å™ªå£°å¹¶æå–ç­‰é•¿ç‰‡æ®µ
                        noise = random.choice(noise_pool)
                        
                        if len(noise) > len(train_audio):
                            start = random.randint(0, len(noise) - len(train_audio))
                            background_noise = noise[start:start + len(train_audio)]
                        else:
                            # å¦‚æœå™ªå£°å¤ªçŸ­ï¼Œé‡å¤å¡«å……
                            repeats = int(np.ceil(len(train_audio) / len(noise)))
                            background_noise = np.tile(noise, repeats)[:len(train_audio)]
                        
                        # ğŸ”§ ä¿®å¤ï¼šæ”¹è¿›åŠŸç‡è®¡ç®—ï¼ˆè€ƒè™‘ç¨€ç–æ€§ï¼‰
                        # è®¡ç®—clicksçš„RMSåŠŸç‡ï¼ˆåŸºäºæ•´ä½“ä¿¡å·ï¼‰
                        signal_rms = np.sqrt(np.mean(train_audio**2))
                        
                        # è®¡ç®—å™ªå£°RMSåŠŸç‡
                        noise_rms = np.sqrt(np.mean(background_noise**2))
                        
                        # æ ¹æ®ç›®æ ‡SNRè®¡ç®—å™ªå£°ç¼©æ”¾å› å­
                        target_snr = random.uniform(*augmenter.snr_range)  # -5 åˆ° 5 dB
                        snr_linear = 10**(target_snr / 10)
                        
                        if noise_rms > 1e-10:
                            # SNR = RMS_signal / RMS_noise
                            # noise_scale = RMS_signal / (SNR * RMS_noise_original)
                            noise_scale = signal_rms / (snr_linear * noise_rms)
                        else:
                            noise_scale = 0
                        
                        # ğŸ”§ é™åˆ¶å™ªå£°ç¼©æ”¾å› å­ï¼ˆé˜²æ­¢å™ªå£°è¿‡å¤§ï¼‰
                        noise_scale = np.clip(noise_scale, 0, 5.0)  # æœ€å¤§5å€
                        
                        # å åŠ æŒç»­çš„èƒŒæ™¯å™ªå£°ï¼ˆå…³é”®æ­¥éª¤ï¼‰
                        train_audio = train_audio + noise_scale * background_noise

                # 5. æœ€ç»ˆå³°å€¼å½’ä¸€åŒ–ï¼ˆé¿å…å‰Šæ³¢ï¼‰
                peak = np.max(np.abs(train_audio))
                if peak > 0:
                    train_audio = train_audio / peak * 0.95
                
                # 6. ä¿å­˜æ ·æœ¬
                train_samples.append({
                    'waveform': train_audio,
                    'label': 1,
                    'file_id': f'click_train_{train_idx:04d}',
                    'candidate_idx': -1,
                    'peak_time': -1,
                    'confidence': 1.0,
                    'n_clicks': n_clicks
                })
                
            except Exception as e:
                print(f"ç”Ÿæˆtrain {train_idx} æ—¶å‡ºé”™: {e}")
                continue
        
        return train_samples
    
    def _place_clicks_with_realistic_ici(self,
                                     clicks: List[np.ndarray],
                                     train_samples_total: int,
                                     ici_range_ms: Tuple[float, float],
                                     sample_rate: int) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨æ›´çœŸå®çš„ICIåˆ†å¸ƒæ”¾ç½®clicks
        
        ç­–ç•¥ï¼š
        1. ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·ICIï¼ˆå‡å€¼=(min+max)/2ï¼Œæ ‡å‡†å·®=(max-min)/6ï¼‰
        2. ç¡®ä¿ICIåœ¨å…è®¸èŒƒå›´å†…
        3. å¦‚æœæ”¾ä¸ä¸‹ï¼Œé‡æ–°å°è¯•
        
        Args:
            clicks: ClickéŸ³é¢‘ç‰‡æ®µåˆ—è¡¨
            train_samples_total: æ€»æ ·æœ¬æ•°
            ici_range_ms: ICIèŒƒå›´ï¼ˆæ¯«ç§’ï¼‰
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            æ”¾ç½®å¥½çš„trainéŸ³é¢‘ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        import random

        # åˆå§‹åŒ–ä¸ºèƒŒæ™¯å™ªéŸ³ï¼ˆè€Œä¸æ˜¯0ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œä¸æ·»åŠ å™ªéŸ³ï¼Œåœ¨å¤–éƒ¨SNRæ··åˆæ—¶æ·»åŠ 
        train_audio = np.zeros(train_samples_total, dtype=np.float32)
        
        # è®¡ç®—ICIåˆ†å¸ƒå‚æ•°ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
        ici_mean_ms = (ici_range_ms[0] + ici_range_ms[1]) / 2
        ici_std_ms = (ici_range_ms[1] - ici_range_ms[0]) / 6  # 99.7%è½åœ¨èŒƒå›´å†…
        
        current_pos = 0
        placements = []
        
        for i, click in enumerate(clicks):
            click_len = len(click)
            
            # ç¡®ä¿ä¸ä¼šè¶Šç•Œ
            if current_pos + click_len > train_samples_total:
                # å°è¯•ä»å¤´é‡æ–°æ”¾ç½®ï¼ˆç»™äº›éšæœºåç§»ï¼‰
                offset = random.randint(0, int(0.1 * sample_rate))  # æœ€å¤š100msåç§»
                if offset + click_len > train_samples_total:
                    return None  # æ”¾ä¸ä¸‹ï¼Œæ”¾å¼ƒæ­¤train
                current_pos = offset
            
            # æ”¾ç½®clickï¼ˆå åŠ ï¼Œé¿å…è¦†ç›–ï¼‰
            end_pos = min(current_pos + click_len, train_samples_total)
            train_audio[current_pos:end_pos] += click[:end_pos-current_pos]
            placements.append(current_pos / sample_rate * 1000)
            
            # è®¡ç®—ä¸‹ä¸€ä¸ªclickçš„ä½ç½®ï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªï¼‰
            if i < len(clicks) - 1:
                # ä»æ­£æ€åˆ†å¸ƒé‡‡æ ·ICI
                for attempt in range(10):  # æœ€å¤šå°è¯•10æ¬¡
                    ici_ms = np.random.normal(ici_mean_ms, ici_std_ms)
                    # é™åˆ¶åœ¨èŒƒå›´å†…
                    ici_ms = np.clip(ici_ms, ici_range_ms[0], ici_range_ms[1])
                    ici_samples = int(ici_ms * sample_rate / 1000)
                    
                    next_pos = current_pos + click_len + ici_samples
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿç©ºé—´
                    if next_pos + len(clicks[i+1]) <= train_samples_total:
                        current_pos = next_pos
                        break
                else:
                    # å°è¯•å¤±è´¥ï¼Œè¿”å›None
                    return None
        
        return train_audio
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _extract_centered_window(self,
                                audio: np.ndarray,
                                center_idx: int) -> Optional[np.ndarray]:
        """Extract window centered on index."""
        half_window = self.window_samples // 2
        start_idx = center_idx - half_window
        end_idx = center_idx + half_window
        
        if start_idx < 0 or end_idx > len(audio):
            segment = self._extract_with_padding(audio, center_idx)
        else:
            segment = audio[start_idx:end_idx]
            
        if len(segment) != self.window_samples:
            return None
            
        segment = self._normalize_segment(segment)
        return segment
        
    def _extract_with_padding(self,
                             audio: np.ndarray,
                             center_idx: int) -> np.ndarray:
        """Extract window with reflection padding if needed."""
        half_window = self.window_samples // 2
        start_idx = center_idx - half_window
        end_idx = center_idx + half_window
        
        pad_left = max(0, -start_idx)
        pad_right = max(0, end_idx - len(audio))
        
        extract_start = max(0, start_idx)
        extract_end = min(len(audio), end_idx)
        
        segment = audio[extract_start:extract_end]
        
        if pad_left > 0 or pad_right > 0:
            segment = np.pad(segment, (pad_left, pad_right), mode='reflect')
            
        return segment
        
    def _normalize_segment(self, segment: np.ndarray) -> np.ndarray:
        """Normalize segment to zero mean and unit variance."""
        segment = segment - np.mean(segment)
        
        mad = np.median(np.abs(segment - np.median(segment)))
        if mad > 1e-10:
            segment = segment / (1.4826 * mad)
        else:
            rms = np.sqrt(np.mean(segment**2))
            if rms > 1e-10:
                segment = segment / rms
                
        return segment.astype(np.float32)
    
    # ========== ä¿å­˜/åŠ è½½æ–¹æ³•ä¿æŒä¸å˜ ==========
    
    def save_dataset(self,
                    samples: List[Dict[str, Any]],
                    output_dir: Path,
                    split: str = 'train') -> Path:
        """Save dataset to disk."""
        split_dir = Path(output_dir) / split
        split_dir.mkdir(parents=True, exist_ok=True)
        
        waveforms = np.array([s['waveform'] for s in samples])
        labels = np.array([s['label'] for s in samples])
        
        np.save(split_dir / 'waveforms.npy', waveforms)
        np.save(split_dir / 'labels.npy', labels)
        
        metadata = []
        for s in samples:
            meta = {k: v for k, v in s.items() if k != 'waveform'}
            metadata.append(meta)
            
        with open(split_dir / 'metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
            
        print(f"Saved {len(samples)} samples to {split_dir}")
        print(f"  Sample shape: {waveforms.shape}")
        print(f"  Positive: {np.sum(labels == 1)}")
        print(f"  Negative: {np.sum(labels == 0)}")
        
        return split_dir
        
    def load_dataset(self, dataset_dir: Path) -> Tuple[np.ndarray, np.ndarray, List[Dict]]:
        """Load dataset from disk."""
        dataset_dir = Path(dataset_dir)
        
        waveforms = np.load(dataset_dir / 'waveforms.npy')
        labels = np.load(dataset_dir / 'labels.npy')
        
        with open(dataset_dir / 'metadata.json', 'r') as f:
            metadata = json.load(f)
            
        return waveforms, labels, metadata
        
    def balance_dataset(self,
                       samples: List[Dict[str, Any]],
                       balance_ratio: float = 1.0) -> List[Dict[str, Any]]:
        """Balance positive and negative samples."""
        positive = [s for s in samples if s['label'] == 1]
        negative = [s for s in samples if s['label'] == 0]
        
        n_positive = len(positive)
        n_negative_target = int(n_positive * balance_ratio)
        
        if len(negative) > n_negative_target:
            negative = random.sample(negative, n_negative_target)
        elif len(negative) < n_negative_target:
            negative = random.choices(negative, k=n_negative_target)
            
        balanced = positive + negative
        random.shuffle(balanced)
        
        return balanced